{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../datasets/Classification/Dataset - 7 dias'\n",
    "CATEGORIES = [\"Normal\", \"Anormal\", \"Morta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "\n",
    "def read_dataset():\n",
    "    images_raw = open(os.path.join(DATASET_PATH, \"7_days_images.pickle\" ), \"rb\")\n",
    "    images = pickle.load(images_raw)\n",
    "\n",
    "    labels_raw = open(os.path.join(DATASET_PATH, \"7_days_labels.pickle\" ), \"rb\")\n",
    "    labels = pickle.load(labels_raw)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Turn it into a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(labels):\n",
    "    labels[labels == 2] = 1\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(images, labels):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.1, stratify=labels)\n",
    "    \n",
    "    print(\"In training:\")\n",
    "    for i in range(0,len(np.unique(labels))):\n",
    "        print(f'Class {i}: {round(100 * np.count_nonzero(np.array(train_labels) == i) / len(train_labels), 2)}%')\n",
    "    print(\"In test:\")\n",
    "    for i in range(0,len(np.unique(labels))):\n",
    "        print(f'Class {i}: {round(100 * np.count_nonzero(np.array(test_labels) == i) / len(test_labels), 2)}%')\n",
    "        \n",
    "    return train_images, test_images, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustando o dataset desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data augmentation -> data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation with ImageDataGenerator -> did not go well\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     validation_split=0.25\n",
    "# )\n",
    "# datagen.fit(train_images)\n",
    "\n",
    "# # it = datagen.flow(train_images, batch_size=1, save_to_dir=\"test\", shuffle= True)\n",
    "\n",
    "# # # generate samples and plot\n",
    "# # for i in range(50):\n",
    "# #      # generate batch of images\n",
    "# #     batch = it.next()\n",
    "# #     # convert to unsigned integers for viewing\n",
    "# #     image = batch[0].astype('uint8')\n",
    "# #     # plot raw pixel data\n",
    "# #     plt.imshow(image, cmap=\"gray\")\n",
    "# #     plt.show()\n",
    "# # show the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weighted Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying class weights\n",
    "# it does not work with one hot encoded data\n",
    "# from sklearn.utils import class_weight\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(train_labels),\n",
    "#                                                  train_labels)\n",
    "\n",
    "def get_sample_weights(train_labels):\n",
    "    from sklearn.utils import compute_sample_weight\n",
    "    \n",
    "    return compute_sample_weight('balanced', train_labels)  #->>>> remember to add the weights in model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes, counts = np.unique(train_labels, return_counts=True)\n",
    "# print(f\"The number of elements for each class in training now are\\nClass 0: {counts[0]}\\nClass 1 {counts[1]}\\nClass 2 {counts[2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "\n",
    "# train_images_shape = train_images.shape\n",
    "# train_images = train_images.reshape((train_images_shape[0], IMG_SIZE * IMG_SIZE * 3))\n",
    "# train_images, train_labels = sm.fit_resample(train_images, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images_shape = train_images.shape\n",
    "# train_images = train_images.reshape((train_images_shape[0], IMG_SIZE, IMG_SIZE, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes, counts = np.unique(train_labels, return_counts=True)\n",
    "# print(f\"The number of elements for each class in training now are\\nClass 0: {counts[0]}\\nClass 1 {counts[1]}\\nClass 2 {counts[2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One hot label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(data):\n",
    "    import pandas as pd\n",
    "    data = pd.get_dummies(data)\n",
    "    data = pd.DataFrame.to_numpy(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(data):\n",
    "    data = tf.keras.utils.normalize(data, axis=0, order=2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import keras\n",
    "import shutil\n",
    "\n",
    "EPOCHS = None\n",
    "TRAIN_TEST_SPLIT = None\n",
    "BATCH_SIZE = None\n",
    "# print((1 - TRAIN_TEST_SPLIT) * train_images.shape[0],BATCH_SIZE)\n",
    "\n",
    "METRICDIR = '../metricas/classificacao/7_d/tests-binary'\n",
    "\n",
    "MODELDIR = os.path.join(METRICDIR, \"adhoc\")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(MODELDIR, \"models\") \n",
    "\n",
    "if os.path.exists(MODELDIR):\n",
    "    shutil.rmtree(MODELDIR)\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "    \n",
    "my_metrics = [\"accuracy\",\n",
    "       tf.keras.metrics.Precision(),\n",
    "       tf.keras.metrics.Recall(),\n",
    "       tf.keras.metrics.AUC(),\n",
    "       tf.keras.metrics.TruePositives(),\n",
    "       tf.keras.metrics.TrueNegatives(),\n",
    "       tf.keras.metrics.FalsePositives(),\n",
    "       tf.keras.metrics.FalseNegatives(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "       \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(   Conv2D(32, (3,3), input_shape=(IMG_SIZE,IMG_SIZE, 3))  )\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Conv2D(16, (3,3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Conv2D(16, (3,3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Conv2D(8, (2,2)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=0.00000000001)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=my_metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)\n",
    "\n",
    "def plot_metric(history,metric_name, chart_name, save_dir, save = False, show = False):\n",
    "    plt.cla() \n",
    "    plt.plot(history.history[metric_name], label = metric_name + ' (training data)')\n",
    "    plt.plot(history.history['val_' + metric_name], label = metric_name + ' (validation data)')\n",
    "    plt.title(chart_name)\n",
    "    plt.ylabel( metric_name + ' value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(save_dir, metric_name))\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    \n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "        \n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "        \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_1d(test_labels):\n",
    "    \n",
    "    test_labels_1d = []\n",
    "    \n",
    "    for label in test_labels:\n",
    "        print()\n",
    "        if (label == [1, 0]).all():\n",
    "            test_labels_1d.append(0)\n",
    "        elif (label == [0, 1]).all():\n",
    "            test_labels_1d.append(1)\n",
    "        else:\n",
    "            test_labels_1d.append(2)\n",
    "    \n",
    "    return test_labels_1d\n",
    "    \n",
    "def get_predictions(model,test_images, test_labels):\n",
    "    prediction = model.predict(test_images, batch_size=1)\n",
    "\n",
    "    return tf.argmax(prediction, axis=-1)\n",
    "\n",
    "def get_confusion_matrix(test_labels, prediction):\n",
    "    \n",
    "    test_labels_1d = one_hot_to_1d(test_labels)\n",
    "    \n",
    "    cm = metrics.confusion_matrix(test_labels_1d, prediction)\n",
    "    cm = make_confusion_matrix(cm, figsize=(8,6), cbar=False)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_models(train_images, train_labels, num_folds=10):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    #metrics containers\n",
    "    acc = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    auc = []\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, test in kfold.split(train_images, train_labels):\n",
    "\n",
    "        from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "        if fold_no - 1 == 0:\n",
    "            idx_str = \"\"\n",
    "        else:\n",
    "            idx_str = f\"_{fold_no}\"\n",
    "            \n",
    "        fold_checkpoint_dir = os.path.join(CHECKPOINT_DIR, get_model_name(fold_no))\n",
    "        \n",
    "        if not os.path.exists(fold_checkpoint_dir):\n",
    "            os.makedirs(fold_checkpoint_dir)\n",
    "        \n",
    "        my_callbacks = [\n",
    "#             ModelCheckpoint(os.path.join(fold_checkpoint_dir,\"model.h5\"), monitor=f\"val_precision\", verbose=1, save_best_only=True, mode='max', save_freq='epoch'),\n",
    "            ReduceLROnPlateau(monitor=f'loss', factor=0.7, patience=2, min_lr=0.00000000001, mode='min'),\n",
    "        ]\n",
    "\n",
    "        model = create_model()\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------', end=\"\\n\\n\")\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model.fit(\n",
    "            train_images[train],\n",
    "            train_labels[train],\n",
    "            batch_size = BATCH_SIZE,\n",
    "            epochs = EPOCHS,\n",
    "            validation_split=TRAIN_TEST_SPLIT,\n",
    "            sample_weight=get_sample_weights(train_labels[train]),\n",
    "            callbacks=[my_callbacks])\n",
    "\n",
    "        predictions = get_predictions(model, train_images[test], train_labels[test])\n",
    "    \n",
    "        cm = get_confusion_matrix(train_labels[test], predictions)\n",
    "        \n",
    "        plt.savefig(os.path.join(fold_checkpoint_dir, \"confusion_matrix\"))\n",
    "        \n",
    "        #visualizing training\n",
    "        NUM_METRICS = len(my_metrics) + 1\n",
    "        for metric in list(history.history.keys())[:NUM_METRICS]:\n",
    "            plot_metric(history, metric, metric + \" for soybean classification\", save_dir=fold_checkpoint_dir, save=True)\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        scores = model.evaluate(images[test], labels[test], verbose=0)\n",
    "        print(f'Scores for fold {fold_no}:')\n",
    "        for i in range(len(my_metrics)):   \n",
    "            print(f'{model.metrics_names[i]} of {scores[i]}')\n",
    "\n",
    "        acc.append(scores[1])\n",
    "        prec.append(scores[2])\n",
    "        rec.append(scores[3])\n",
    "        auc.append(scores[4])\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "        \n",
    "    return acc, prec, rec, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = read_dataset()\n",
    "\n",
    "images = normalize_images(images)\n",
    "labels = to_binary(labels)\n",
    "labels = to_one_hot(labels)\n",
    "\n",
    "EPOCHS = 20\n",
    "TRAIN_TEST_SPLIT = 0.25\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 58s 2s/step - loss: 1.1042 - accuracy: 0.5545 - precision: 0.5208 - recall: 0.5024 - auc: 0.4957 - true_positives: 218.6538 - true_negatives: 226.0769 - false_positives: 204.5385 - false_negatives: 211.9615 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.1178 - accuracy: 0.5715 - precision: 0.5212 - recall: 0.5190 - auc: 0.4961 - true_positives: 222.4231 - true_negatives: 227.5000 - false_positives: 203.1154 - false_negatives: 208.1923 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.0576 - accuracy: 0.5726 - precision: 0.5238 - recall: 0.5282 - auc: 0.4983 - true_positives: 226.6923 - true_negatives: 227.6154 - false_positives: 203.0000 - false_negatives: 203.9231 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.0139 - accuracy: 0.5709 - precision: 0.5328 - recall: 0.5093 - auc: 0.4963 - true_positives: 221.3077 - true_negatives: 232.3846 - false_positives: 198.2308 - false_negatives: 209.3077 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 41s 2s/step - loss: 1.1439 - accuracy: 0.5675 - precision: 0.5334 - recall: 0.5346 - auc: 0.4972 - true_positives: 227.6923 - true_negatives: 227.4615 - false_positives: 203.1538 - false_negatives: 202.9231 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 39s 2s/step - loss: 1.0644 - accuracy: 0.5542 - precision: 0.5266 - recall: 0.5209 - auc: 0.4982 - true_positives: 223.7308 - true_negatives: 228.9231 - false_positives: 201.6923 - false_negatives: 206.8846 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 38s 2s/step - loss: 1.0766 - accuracy: 0.5744 - precision: 0.5311 - recall: 0.5233 - auc: 0.4973 - true_positives: 225.1154 - true_negatives: 230.0385 - false_positives: 200.5769 - false_negatives: 205.5000 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.1464 - accuracy: 0.5634 - precision: 0.5206 - recall: 0.5112 - auc: 0.4914 - true_positives: 223.5769 - true_negatives: 227.6538 - false_positives: 202.9615 - false_negatives: 207.0385 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 31s 1s/step - loss: 1.1323 - accuracy: 0.5525 - precision: 0.5283 - recall: 0.5329 - auc: 0.4970 - true_positives: 225.0385 - true_negatives: 228.5000 - false_positives: 202.1154 - false_negatives: 205.5769 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 33s 1s/step - loss: 1.0523 - accuracy: 0.5910 - precision: 0.5305 - recall: 0.5369 - auc: 0.4977 - true_positives: 229.6154 - true_negatives: 227.5000 - false_positives: 203.1154 - false_negatives: 201.0000 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 34s 1s/step - loss: 1.1509 - accuracy: 0.5524 - precision: 0.5347 - recall: 0.5051 - auc: 0.4994 - true_positives: 217.0385 - true_negatives: 236.4615 - false_positives: 194.1538 - false_negatives: 213.5769 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 35s 1s/step - loss: 1.0950 - accuracy: 0.5866 - precision: 0.5339 - recall: 0.5293 - auc: 0.4945 - true_positives: 225.4615 - true_negatives: 231.0769 - false_positives: 199.5385 - false_negatives: 205.1538 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 36s 1s/step - loss: 1.0728 - accuracy: 0.5833 - precision: 0.5358 - recall: 0.5088 - auc: 0.4958 - true_positives: 220.8462 - true_negatives: 233.8077 - false_positives: 196.8077 - false_negatives: 209.7692 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 33s 1s/step - loss: 1.0896 - accuracy: 0.5825 - precision: 0.5317 - recall: 0.5089 - auc: 0.4974 - true_positives: 221.8077 - true_negatives: 233.3077 - false_positives: 197.3077 - false_negatives: 208.8077 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 40s 2s/step - loss: 1.2305 - accuracy: 0.5620 - precision: 0.5294 - recall: 0.5127 - auc: 0.4936 - true_positives: 222.4615 - true_negatives: 231.8462 - false_positives: 198.7692 - false_negatives: 208.1538 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 39s 2s/step - loss: 1.0756 - accuracy: 0.5392 - precision: 0.5190 - recall: 0.5403 - auc: 0.4974 - true_positives: 230.3462 - true_negatives: 220.6923 - false_positives: 209.9231 - false_negatives: 200.2692 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 35s 1s/step - loss: 1.0726 - accuracy: 0.5620 - precision: 0.5159 - recall: 0.5026 - auc: 0.4993 - true_positives: 222.3077 - true_negatives: 226.0769 - false_positives: 204.5385 - false_negatives: 208.3077 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 34s 1s/step - loss: 1.0339 - accuracy: 0.5560 - precision: 0.5240 - recall: 0.5346 - auc: 0.4935 - true_positives: 230.1154 - true_negatives: 223.4231 - false_positives: 207.1923 - false_negatives: 200.5000 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 38s 2s/step - loss: 1.0507 - accuracy: 0.5472 - precision: 0.5254 - recall: 0.5313 - auc: 0.4989 - true_positives: 226.5385 - true_negatives: 228.4615 - false_positives: 202.1538 - false_negatives: 204.0769 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 40s 2s/step - loss: 1.1481 - accuracy: 0.5625 - precision: 0.5295 - recall: 0.5181 - auc: 0.4957 - true_positives: 223.5385 - true_negatives: 232.0769 - false_positives: 198.5385 - false_negatives: 207.0769 - val_loss: 0.9337 - val_accuracy: 0.5655 - val_precision: 0.5349 - val_recall: 0.5169 - val_auc: 0.5075 - val_true_positives: 138.0000 - val_true_negatives: 147.0000 - val_false_positives: 120.0000 - val_false_negatives: 129.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7a77ef3c5a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-9c57a2ea44d3>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(train_images, train_labels, num_folds)\u001b[0m\n\u001b[1;32m     48\u001b[0m             callbacks=[my_callbacks])\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9c3642b70e63>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model, test_images, test_labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "acc, prec, rec, auc = train_models(images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the best model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acurácia média: \",np.mean(acc))\n",
    "print(\"Precisão média: \",np.mean(prec))\n",
    "print(\"Recall médio: \",np.mean(rec))\n",
    "print(\"Auc média: \",np.mean(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_1d = []\n",
    "for label in test_labels:\n",
    "    if (label == [1, 0, 0]).all():\n",
    "        test_labels_1d.append(0)\n",
    "    elif (label == [0, 1, 0]).all():\n",
    "        test_labels_1d.append(1)\n",
    "    else:\n",
    "        test_labels_1d.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_images, batch_size=1)\n",
    "\n",
    "prediction = tf.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    \n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cm = metrics.confusion_matrix(test_labels_1d, prediction)\n",
    "\n",
    "make_confusion_matrix(cm, figsize=(8,6), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_labels_1d, prediction, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
