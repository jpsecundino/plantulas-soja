{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '../datasets/Classification/Dataset - 3 dias/Images'\n",
    "CATEGORIES = [\"Normal\", \"Anormal\", \"Morta\"]\n",
    "\n",
    "##loading images for classification\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "            ## add images to training data with its label\n",
    "            training_data.append([img_array, class_num])\n",
    "    return training_data\n",
    "            \n",
    "training_data = create_training_data()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mix data for better learning\n",
    "import random\n",
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image, label in training_data:\n",
    "    images.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##saving dataset\n",
    "import pickle\n",
    "DATASET_PATH = \"../datasets/Classification/Dataset - 3 dias/\"\n",
    "\n",
    "pickle_out = open(os.path.join(DATASET_PATH, \"3_days_images.pickle\"), \"wb\")\n",
    "pickle.dump(images, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(os.path.join(DATASET_PATH, \"3_days_labels.pickle\"), \"wb\")\n",
    "pickle.dump(labels, pickle_out)\n",
    "pickle_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classificatin model\n",
    "##### Following this tutorial\n",
    "       www.youtube.com/watch?v=WvoLTXIjBYU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "images_raw = open(os.path.join(DATASET_PATH, \"3_days_images.pickle\" ), \"rb\")\n",
    "images = pickle.load(images_raw)\n",
    "\n",
    "labels_raw = open(os.path.join(DATASET_PATH, \"3_days_labels.pickle\" ), \"rb\")\n",
    "labels = pickle.load(labels_raw)\n",
    "\n",
    "#reshape images\n",
    "IMG_SIZE = 256\n",
    "\n",
    "for i in range(0, len(images)):\n",
    "    images[i] = cv2.resize(images[i], dsize=(IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "    images[i] = np.array(images[i])\n",
    "    labels[i] = np.array(labels[i])\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "labels_test = labels.reshape(-1,1)\n",
    "\n",
    "##one hot \n",
    "import pandas as pd\n",
    "\n",
    "labels = pd.get_dummies(labels)\n",
    "labels = pd.DataFrame.to_numpy(labels)\n",
    "\n",
    "#normalizing images    \n",
    "images = tf.keras.utils.normalize(images, axis=0, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(labels[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "26/26 [==============================] - 55s 2s/step - loss: 0.6629 - accuracy: 0.7145 - val_loss: 0.3047 - val_accuracy: 0.8696\n",
      "Epoch 2/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.2458 - accuracy: 0.9148 - val_loss: 0.2712 - val_accuracy: 0.8841\n",
      "Epoch 3/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.2257 - accuracy: 0.9142 - val_loss: 0.2944 - val_accuracy: 0.8877\n",
      "Epoch 4/25\n",
      "26/26 [==============================] - 47s 2s/step - loss: 0.1914 - accuracy: 0.9219 - val_loss: 0.3704 - val_accuracy: 0.8478\n",
      "Epoch 5/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1659 - accuracy: 0.9149 - val_loss: 0.3664 - val_accuracy: 0.8696\n",
      "Epoch 6/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.1345 - accuracy: 0.9390 - val_loss: 0.3299 - val_accuracy: 0.8804\n",
      "Epoch 7/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.1173 - accuracy: 0.9437 - val_loss: 0.3960 - val_accuracy: 0.8696\n",
      "Epoch 8/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.1026 - accuracy: 0.9548 - val_loss: 0.3868 - val_accuracy: 0.8877\n",
      "Epoch 9/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.0771 - accuracy: 0.9730 - val_loss: 0.4315 - val_accuracy: 0.8551\n",
      "Epoch 10/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0568 - accuracy: 0.9794 - val_loss: 0.5158 - val_accuracy: 0.8768\n",
      "Epoch 11/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0471 - accuracy: 0.9811 - val_loss: 0.6220 - val_accuracy: 0.8514\n",
      "Epoch 12/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0336 - accuracy: 0.9869 - val_loss: 0.7395 - val_accuracy: 0.8732\n",
      "Epoch 13/25\n",
      "26/26 [==============================] - 50s 2s/step - loss: 0.0121 - accuracy: 0.9996 - val_loss: 0.9223 - val_accuracy: 0.8623\n",
      "Epoch 14/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.7754 - val_accuracy: 0.8768\n",
      "Epoch 15/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.8596 - val_accuracy: 0.8551\n",
      "Epoch 16/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.9176 - val_accuracy: 0.8587\n",
      "Epoch 17/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 1.1191 - val_accuracy: 0.8659\n",
      "Epoch 18/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9655 - val_accuracy: 0.8478\n",
      "Epoch 19/25\n",
      "26/26 [==============================] - 48s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.8696\n",
      "Epoch 20/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 6.0746e-04 - accuracy: 1.0000 - val_loss: 1.1951 - val_accuracy: 0.8623\n",
      "Epoch 21/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 4.5593e-04 - accuracy: 1.0000 - val_loss: 1.2399 - val_accuracy: 0.8659\n",
      "Epoch 22/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 2.6221e-04 - accuracy: 1.0000 - val_loss: 1.2636 - val_accuracy: 0.8659\n",
      "Epoch 23/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 1.9554e-04 - accuracy: 1.0000 - val_loss: 1.2833 - val_accuracy: 0.8623\n",
      "Epoch 24/25\n",
      "26/26 [==============================] - 49s 2s/step - loss: 2.2265e-04 - accuracy: 1.0000 - val_loss: 1.2975 - val_accuracy: 0.8659\n",
      "Epoch 25/25\n",
      "26/26 [==============================] - 51s 2s/step - loss: 2.4736e-04 - accuracy: 1.0000 - val_loss: 1.3217 - val_accuracy: 0.8623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34c0900550>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "TRAIN_TEST_SPLIT = 0.25\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(   Conv2D(64, (3,3), input_shape=images.shape[1:])   )\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "model.fit(images, labels, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split=TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 13s 360ms/step - loss: 0.1799 - accuracy: 0.9328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1798994541168213, 0.9327883720397949]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(images, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
